{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv,random\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import uniform\n",
    "#load all the functions\n",
    "#%run  myfunctions.ipynb\n",
    "#%run  surrogate_agg.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "%run  surrogate_agg.ipynb\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "save_file = open('daily_HFC_multi_outcome_data_matrix_all.npy','rb')\n",
    "indicator = np.load(save_file)\n",
    "preds = np.load(save_file)\n",
    "conf = np.load(save_file)\n",
    "wager = np.load(save_file)\n",
    "se = np.load(save_file)\n",
    "truth = np.load(save_file)\n",
    "openday = np.load(save_file)\n",
    "user_type = np.load(save_file)\n",
    "user_id = np.load(save_file)\n",
    "save_file.close()\n",
    "\n",
    "ifps_data = pd.read_csv(\"ifps0726_resolved.csv\")\n",
    "ifps_type = ifps_data['type'].values\n",
    "\n",
    "\n",
    "#save_file = open('daily_HFC_data_matrix_agg.npy','rb')\n",
    "#agg_preds = np.load(save_file)\n",
    "#agg_se = np.load(save_file)\n",
    "##agg_openday = np.load(save_file)\n",
    "### Truth a vector of {1,2} where 1 means the event happen with probability 1\n",
    "##truth = np.load(save_file)\n",
    "#save_file.close()\n",
    "\n",
    "\n",
    "#preds = np.loadtxt(fname=\"/Users/heliaguin/Academy/EconCS/GJP_data/preds_matrix.csv\", delimiter=',', dtype=float)\n",
    "#truth = np.loadtxt(fname=\"/Users/heliaguin/Academy/EconCS/GJP_data/truth_vector.csv\", delimiter=',', dtype=int)\n",
    "#wager = np.ones_like(preds)\n",
    "#conf = np.ones_like(preds)\n",
    "#mse = np.ones_like(preds)\n",
    "\n",
    "\n",
    "#print(preds)\n",
    "print(ifps_type)\n",
    "print(truth)\n",
    "print(preds.shape)\n",
    "print(conf.shape)\n",
    "print(wager.shape)\n",
    "print(se.shape)\n",
    "print(openday.shape)\n",
    "print(user_type.shape)\n",
    "print(user_id.shape)\n",
    "print(user_id)\n",
    "#print(openday[35:70].T)\n",
    "#print(agg_openday[35:70].T)\n",
    "#print(ifps_data[['map_id','type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sur_error_rate(preds_matrix, eval_labels, P0=0.51, kappa=0.02):\n",
    "#compute the error rates\n",
    "#multi-testing for selecting the right solution for error rates\n",
    "\n",
    "    label_matrix = np.zeros_like(preds_matrix, dtype=int)\n",
    "    label_matrix[preds_matrix>=0.5] = 1\n",
    "    label_matrix[preds_matrix<0.5] = 2\n",
    "    label_matrix[preds_matrix<0] = -1\n",
    "    \n",
    "    #compute the error rates\n",
    "    #multi-testing for selecting the right solution for error rates\n",
    "\n",
    "    num_q = int(len(label_matrix))\n",
    "    num_w = len(label_matrix[0])\n",
    "    print(num_q,num_w)\n",
    "\n",
    "    num_hypo = 11\n",
    "    cnt_l = 0\n",
    "    cnt_h = 0\n",
    "    p0_l = []\n",
    "    p1_l = []\n",
    "    P0_est_l = []\n",
    "    P1_post_l = []\n",
    "    p0_h = []\n",
    "    p1_h = []\n",
    "    P0_est_h = []\n",
    "    P1_post_h = []\n",
    "\n",
    "    for t in range(num_hypo):\n",
    "        kk = int(np.ceil(num_w*2))\n",
    "        train_data = []\n",
    "        train_data_Y = []\n",
    "        for q in range(int(num_q/1)):\n",
    "            ans_temp = label_matrix[q][:]\n",
    "            list_taken = [] # extract the list of valid answers. \n",
    "            for ii in range(len(ans_temp)):\n",
    "                if float(ans_temp[ii]) > 0: # -1 is regarded as not taking the task\n",
    "                    list_taken.append(ii)\n",
    "            #print list_taken\n",
    "            \n",
    "            data_temp = [float(ans_temp[x])-1 for x in list_taken]\n",
    "            for k in range(kk):\n",
    "                if len(data_temp)<3: continue\n",
    "                data_temp2 = random.sample(data_temp,3)\n",
    "                train_data.append(data_temp2)\n",
    "        \n",
    "        p0,p1,P0_est,ind = error_rate_priorfree(P0,train_data)\n",
    "        print(p0,p1,ind)\n",
    "        if (max(p0,p1) <= 1) & (min(p0,p1) > 0):\n",
    "            if ind == 1:\n",
    "                cnt_l = cnt_l + 1\n",
    "                p0_l.append(p0)\n",
    "                p1_l.append(p1)\n",
    "                P0_est_l.append(P0_est)\n",
    "                #P1_post_l.append(P1_post)\n",
    "            else:\n",
    "                cnt_h = cnt_h + 1\n",
    "                p0_h.append(p0)\n",
    "                p1_h.append(p1)\n",
    "                P0_est_h.append(P0_est)\n",
    "                #P1_post_h.append(P1_post)\n",
    "\n",
    "    print(np.mean(p0_l),np.mean(p1_l))\n",
    "    print(np.mean(p0_h),np.mean(p1_h))\n",
    "\n",
    "    if cnt_l >= cnt_h:\n",
    "        p0 = np.mean(p0_l)\n",
    "        p1 = np.mean(p1_l)\n",
    "        P0_est = np.mean(P0_est_l)\n",
    "        #P1_post = np.mean(P1_post_l)\n",
    "    else:\n",
    "        p0 = np.mean(p0_h)\n",
    "        p1 = np.mean(p1_h)\n",
    "        P0_est = np.mean(P0_est_h)\n",
    "        #P1_post = np.mean(P1_post_h)\n",
    "\n",
    "        \n",
    "    print('Estimated e0,e1,P0:~',p0,p1,P0_est)#,P1_post\n",
    "    if np.isnan(p0) or np.isnan(p1) or np.isnan(P0_est):\n",
    "        return np.NAN, np.NAN\n",
    "    \n",
    "    ###count in individual error rates\n",
    "    err_ind = []\n",
    "    for ww in range(len(eval_labels[0])):\n",
    "        kk = 1000\n",
    "        train_data = []\n",
    "        ind_predict = []\n",
    "        #q_list = [] #\n",
    "        #for q in range(int(num_q/1)): #\n",
    "        #    if float(label_matrix[q][ww]) > 0: #\n",
    "        #        q_list.append(q) #\n",
    "        q_list = [qid for qid in range(num_q)]\n",
    "        \n",
    "        for q in q_list:\n",
    "            ans_temp = label_matrix[q][:]\n",
    "            list_taken = [] # extract the list of valid answers. \n",
    "            for ii in range(len(ans_temp)):\n",
    "                if float(ans_temp[ii]) > 0: # -1 is regarded as not taking the task\n",
    "                    list_taken.append(ii)\n",
    "            #print list_taken\n",
    "            \n",
    "            data_temp = [float(ans_temp[x])-1 for x in list_taken]\n",
    "            for k in range(kk):\n",
    "                ind_predict.append(float(eval_labels[q][ww])-1)\n",
    "                data_temp2 = random.sample(data_temp,1)\n",
    "                train_data.append(data_temp2[0])\n",
    "   \n",
    "        p0_m,p1_m = machine_error(P0_est,p0,p1,train_data, ind_predict)\n",
    "\n",
    "        if abs(p0_m) <= 0.05:\n",
    "            p0_m = 0\n",
    "        if abs(p1_m) <= 0.05:\n",
    "            p1_m = 0\n",
    "            \n",
    "        if abs(p0_m-1) <= 0.05:\n",
    "            p0_m = 1\n",
    "        if abs(p1_m-1) <= 0.05:\n",
    "            p1_m = 1\n",
    "            \n",
    "        err_ind.append([p0_m,p1_m])\n",
    "        \n",
    "    for pp in err_ind:\n",
    "        if pp[0]<-0.2 or pp[0]>1.2 or pp[1]<-0.2 or pp[1]>1.2:\n",
    "            #pp[0], pp[1] = 0.5, 0.5\n",
    "            continue\n",
    "        else:\n",
    "            pp[0] = max(min(pp[0],1-kappa),kappa)\n",
    "            pp[1] = max(min(pp[1],1-kappa),kappa)\n",
    "    return err_ind, P0_est\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def surrogate_Brier(forecast, outcome, error0, error1):\n",
    "    n = len(forecast)\n",
    "    score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        p = forecast[i]\n",
    "        e0 = error0[i]\n",
    "        e1 = error1[i]\n",
    "        if outcome[i] == 1:\n",
    "            score[i] = ((1 - e0) * (2 * (1 - p)**2) - e1 * (2 * p**2)) / (1 - e1 - e0)\n",
    "        else:\n",
    "            score[i] = ((1 - e1) * (2 * p**2) - e0 * (2 * (1 - p)**2)) / (1 - e1 - e0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def logit_aggr(preds, ifps_type=None, para={2: 1.4, 3: 1.4, 4: 1.4, 5: 1.4}):\n",
    "    n, m, k = preds.shape\n",
    "    if ifps_type is None: ifps_type = 2 * np.ones(n)\n",
    "    logit_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        num_outcome = int(ifps_type[i])\n",
    "        a = para[num_outcome]\n",
    "        curr_pred = preds[i, preds[i, :, 0]>-0.1, :]\n",
    "        if (np.sum(curr_pred[:, 0]>-0.1)<=0): continue\n",
    "        logit_pred[i] = 0\n",
    "        base_dim = 0#ifps_type[i] - 1\n",
    "        logits = np.array(curr_pred).T\n",
    "        logits[base_dim, logits[base_dim]>=1] = 0.999\n",
    "        logits[base_dim, logits[base_dim]<=0] = 0.001\n",
    "        logit_pred[i, base_dim] = 1\n",
    "        for k in range(0, num_outcome):\n",
    "            if k==base_dim: continue\n",
    "            logits[k, logits[k]>=1] = 0.999\n",
    "            logits[k, logits[k]<=0] = 0.001\n",
    "            logits[k] = np.log(logits[k]/logits[base_dim])\n",
    "            mean = np.mean(logits[k])\n",
    "            logit_pred[i, k] = np.exp(a * mean)\n",
    "        logit_pred[i] = logit_pred[i] / np.sum(logit_pred[i])\n",
    "        #print(\"qid: \", i, \"type: \", ifps_type[i], \"logit: \", logit_pred[i])\n",
    "        \n",
    "    return logit_pred\n",
    "\n",
    "def mean_aggr_binary(preds):\n",
    "    n, m = preds.shape\n",
    "    mean_pred = -np.ones(n)\n",
    "    for i in range(n):\n",
    "        valid = preds[i]>-0.1\n",
    "        if (np.sum(valid)<=0): continue\n",
    "        mean_pred[i] = np.mean(preds[i][valid])\n",
    "    return mean_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "binary_ifps = ifps_type == 2\n",
    "last_pred = preds[-1][binary_ifps, :, 0]\n",
    "n = last_pred.shape[0]\n",
    "#truth = 2-truth[binary_ifps]\n",
    "#agg_pred = logit_agg_binary(last_pred)\n",
    "agg_pred = mean_aggr_binary(last_pred)\n",
    "\n",
    "print(agg_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trials = 100\n",
    "agg_labels_multi_trials = np.zeros((n, trials))\n",
    "for i in range(trials):\n",
    "    labels = 2 - (np.random.rand(n) < agg_pred)\n",
    "    agg_labels_multi_trials[:, i] = labels\n",
    "agg_labels_multi_trials[:, 0] = 2 - (0.5 < agg_pred)\n",
    "print(agg_labels_multi_trials[:, 0])\n",
    "print(agg_labels_multi_trials.shape)\n",
    "print(agg_labels_multi_trials)\n",
    "err_ind, P0_est = sur_error_rate(last_pred, eval_labels=agg_labels_multi_trials)\n",
    "#err_ind, P0_est = sur_error_rate(last_pred, eval_labels=agg_labels_multi_trials[:, 0][:,None], P0=0.49)\n",
    "err_ind = np.array(err_ind)\n",
    "err_agg = np.mean(err_ind, axis=0)\n",
    "print(err_agg)\n",
    "print(err_ind.shape)\n",
    "print(err_ind)\n",
    "print(P0_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_sur_score(preds, agg_pred, agg_err):\n",
    "    n, m = preds.shape\n",
    "\n",
    "    score = np.NAN * np.ones(preds.shape)\n",
    "    for j in range(m):\n",
    "        curr_pred = preds[:, j]\n",
    "        valid = curr_pred>=0.0\n",
    "        curr_pred = curr_pred[valid]\n",
    "        answerred_ifps_num = np.sum(valid)\n",
    "        curr_score = np.zeros(answerred_ifps_num)\n",
    "        e0, e1 = agg_err\n",
    "        e1 = e1 * np.ones(answerred_ifps_num)\n",
    "        e0 = e0 * np.ones(answerred_ifps_num)\n",
    "        curr_score = (agg_pred[valid] * surrogate_Brier(curr_pred, np.ones(answerred_ifps_num), e0, e1) \n",
    "                      + (1-agg_pred[valid]) * surrogate_Brier(curr_pred, np.zeros(answerred_ifps_num), e0, e1))\n",
    "        score[valid, j] = curr_score\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(agg_labels_multi_trials[:, 0].shape)\n",
    "#sur_score_matrix = estimate_sur_score(last_pred, agg_labels_multi_trials[:, 0], err_agg)\n",
    "sur_score_matrix = estimate_sur_score(last_pred, agg_pred, err_agg)\n",
    "print(np.min(sur_score_matrix[~np.isnan(sur_score_matrix)]),\n",
    "      np.max(sur_score_matrix[~np.isnan(sur_score_matrix)]))\n",
    "print(np.nanmean(sur_score_matrix))\n",
    "print(sur_score_matrix)\n",
    "#sur_score = estimate_sur_score(np.array(1 * (0.5 < agg_pred))[:, None], agg_pred[:], err_agg)\n",
    "#sur_score = estimate_sur_score(0.5 * np.ones((n,1)), agg_pred, err_agg)\n",
    "#print(sur_score)\n",
    "#print(np.mean(sur_score))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "ind_mean_sur_score = np.nanmean(sur_score_matrix, axis=0)\n",
    "print(ind_mean_sur_score.shape)\n",
    "#se_matrix = se[binary_ifps]\n",
    "se_matrix = se[-1][binary_ifps]\n",
    "se_matrix[se_matrix==-1] = np.NAN\n",
    "ind_mean_se = np.nanmean(se_matrix, axis=0)\n",
    "print(ind_mean_se.shape)\n",
    "plt.figure(1)\n",
    "x = ind_mean_se[np.sum(last_pred[:, :]>=0, axis=0)>=0]\n",
    "y = ind_mean_sur_score[np.sum(last_pred[:, :]>=0, axis=0)>=0]\n",
    "x = x[~np.isnan(y)]\n",
    "y = y[~np.isnan(y)]\n",
    "print('Correlation:')\n",
    "print(st.pearsonr(x, y))\n",
    "plt.plot(x, y, '.', label=\"Individual's mean score pair\")\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "a1, a2 = np.linalg.lstsq(A, y)[0]\n",
    "x = np.linspace(np.min(x),np.max(x),20)\n",
    "plt.plot(x, x * a1 + a2)\n",
    "plt.xlabel('Mean B.S. over Binary IFPs')\n",
    "plt.ylabel('Mean S.S. over Binary IFPs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "plt.figure(2)\n",
    "valid_sur_score_matrix = sur_score_matrix[:][~np.isnan(sur_score_matrix[:])].flatten()\n",
    "valid_se_matrix = se_matrix[:][~np.isnan(se_matrix[:])].flatten()\n",
    "print('Correlation:')\n",
    "print(st.pearsonr(valid_se_matrix, valid_sur_score_matrix))\n",
    "plt.plot(valid_se_matrix, valid_sur_score_matrix, '.', label=\"Score pair of a prediction\")\n",
    "interval = 40\n",
    "x = np.linspace(0, 2, interval+1)\n",
    "y = []\n",
    "for c in x:\n",
    "    half_slot = (2/interval) / 2\n",
    "    y.append(np.mean(valid_sur_score_matrix[(valid_se_matrix>=c-half_slot) & (valid_se_matrix<c+half_slot)]))\n",
    "plt.plot(x, y, '*')\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "a1, a2 = np.linalg.lstsq(A, y)[0]\n",
    "x = np.linspace(np.min(x),np.max(x),20)\n",
    "plt.plot(x, x * a1 + a2,'r')\n",
    "plt.xlabel('Brier Score')\n",
    "plt.ylabel('Surrogate Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "\n",
    "print(agg_pred)\n",
    "\n",
    "print(surrogate_Brier([1.0], [1.0], error0=[err_agg[0]], error1=[err_agg[1]]))\n",
    "print(surrogate_Brier([1.0], [0.0], error0=[err_agg[0]], error1=[err_agg[1]]))\n",
    "print(surrogate_Brier([0.0], [0.0], error0=[err_agg[0]], error1=[err_agg[1]]))\n",
    "print(surrogate_Brier([0.0], [1.0], error0=[err_agg[0]], error1=[err_agg[1]]))\n",
    "\n",
    "plt.figure(3)\n",
    "se_matrix = se[-1]\n",
    "se_matrix[se_matrix==-1] = np.NAN\n",
    "ind_mean_se = np.nanmean(se_matrix, axis=0)\n",
    "x = ind_mean_se[np.sum(preds[-1][:, :, 0]>=0, axis=0)>=0]\n",
    "y = ind_mean_sur_score[np.sum(preds[-1][:, :, 0]>=0, axis=0)>=0]\n",
    "x = x[~np.isnan(y)]\n",
    "y = y[~np.isnan(y)]\n",
    "print('Correlation:')\n",
    "print(st.pearsonr(x, y))\n",
    "plt.plot(x, y, '.', label=\"Individual's Mean score pair\")\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "a1, a2 = np.linalg.lstsq(A, y)[0]\n",
    "x = np.linspace(np.min(x),np.max(x),20)\n",
    "plt.plot(x, x * a1 + a2)\n",
    "plt.xlabel('Mean B.S. accross All IFPs')\n",
    "plt.ylabel('Mean S.S. accross Binary IFPs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(4)\n",
    "se_matrix = se[-4]\n",
    "se_matrix[se_matrix==-1] = np.NAN\n",
    "ind_mean_se = np.nanmean(se_matrix, axis=0)\n",
    "x = ind_mean_se[np.sum(preds[-1][:, :, 0]>=0, axis=0)>=0]\n",
    "y = np.nanmean(se_matrix[binary_ifps], axis=0)[np.sum(preds[-1][:, :, 0]>=0, axis=0)>=0]\n",
    "x = x[~np.isnan(y)]\n",
    "y = y[~np.isnan(y)]\n",
    "print('Correlation:')\n",
    "print(st.pearsonr(x, y))\n",
    "plt.plot(x, y, '.', label=\"Individual's mean score pair\")\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "a1, a2 = np.linalg.lstsq(A, y)[0]\n",
    "x = np.linspace(np.min(x),np.max(x),20)\n",
    "plt.plot(x, x * a1 + a2)\n",
    "plt.xlabel('Individual Mean Brier Score accross all IFPs')\n",
    "plt.ylabel('Individual Mean Brier Score accross binary IFPs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(sur_score_matrix.shape)\n",
    "print(binary_ifps.shape)\n",
    "full_sur_score_matrix = np.NAN * np.ones_like(preds[-1][:,:,0])\n",
    "print(full_sur_score_matrix.shape)\n",
    "full_sur_score_matrix[binary_ifps, :] = sur_score_matrix\n",
    "save_file = open('sur_score_matrix0726.npy','wb')\n",
    "np.save(save_file, full_sur_score_matrix)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
