{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run  surrogate_agg.ipynb\n",
    "%run  surrogate_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sur_weighted_aggr(preds, sur_score_matrix, ifps_type=None):\n",
    "    n, m, k = preds.shape\n",
    "    if ifps_type is None:\n",
    "        ifps_type = 2 * np.ones(n)\n",
    "    sur_weighted_pred = -1 * np.ones((n, k))\n",
    "    #ind_mean_sur_score = np.nanmean(sur_score_matrix, axis=0) \n",
    "    scaled_score = np.array(sur_score_matrix) \n",
    "    ### for Brier Score\n",
    "    #scaled_score[scaled_score==-1] = np.NAN\n",
    "    #scaled_score = 2-scaled_score\n",
    "    ### for sur score (sur score contains negetive values)\n",
    "    scaled_score = ((np.nanmax(scaled_score, axis=1)[:, None] - scaled_score) / \n",
    "                    (np.nanmax(scaled_score, axis=1)[:, None]-np.nanmin(scaled_score, axis=1)[:, None])) * 2\n",
    "    scaled_score = scaled_score - (np.nanmedian(scaled_score, axis=1)[:, None]\n",
    "                                   -np.abs(np.nanmedian(scaled_score, axis=1)[:, None])*0.3)\n",
    "    ind_mean_sur_score = np.nansum(scaled_score, axis=0)\n",
    "        \n",
    "    \n",
    "    for i in range(n):\n",
    "        curr_pred = preds[i]\n",
    "        curr_score = np.array(ind_mean_sur_score)\n",
    "        curr_score[np.isnan(curr_score) | np.isnan(curr_pred[:, 0])] = -1000\n",
    "        user_seq = np.argsort(curr_score)\n",
    "            \n",
    "        num_answerred_users = np.sum(curr_score>-1000)\n",
    "        threshold = np.min([np.max([np.min([int(np.ceil(num_answerred_users*0.1)), 20]), 5]),\n",
    "                            num_answerred_users])\n",
    "        #print(i, ifps_type[i], num_answerred_users, threshold, np.sum(~np.isnan(ind_mean_sur_score)))\n",
    "        if threshold<=0: continue\n",
    "        #print(curr_pred[user_seq[-threshold:]][:, 0])\n",
    "        #print(curr_pred[user_seq[-num_answerred_users:]][:, 0])\n",
    "        curr_pred = curr_pred[user_seq[-threshold:]]\n",
    "        weights = curr_score[user_seq[-threshold:]]\n",
    "        if (np.max(weights)-np.min(weights)!=0.):\n",
    "            weights = (weights - np.min(weights))/(np.max(weights)-np.min(weights))\n",
    "        weights = np.exp(weights)\n",
    "        sur_weighted_pred[i] = np.average(curr_pred, weights=weights, axis=0)\n",
    "        #sur_weighted_pred[i] = median_aggr(curr_pred[None, :,:]).squeeze()\n",
    "        #sur_weighted_pred[i] = entropy_weighted_aggr(curr_pred[None, :,:], ifps_type=[ifps_type[i]])\n",
    "        #sur_weighted_pred[i] = conf_weighted_aggr(curr_pred[None, :,:], \n",
    "        #                                          conf[i, user_seq[-threshold:]][None, :])\n",
    "        #print(sur_weighted_pred[i])\n",
    "    #print(np.isnan(scaled_score).any())\n",
    "    return sur_weighted_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file = open('data0928/daily_data_matrix_all_0928.npy','rb')\n",
    "raw_indicator = np.load(save_file)\n",
    "raw_preds = np.load(save_file)\n",
    "raw_conf = np.load(save_file)\n",
    "raw_wager = np.load(save_file)\n",
    "raw_se = np.load(save_file)\n",
    "raw_truth = np.load(save_file)\n",
    "raw_openday = np.load(save_file)\n",
    "raw_user_type = np.load(save_file)\n",
    "raw_user_id = np.load(save_file)\n",
    "raw_preds_age = np.load(save_file)\n",
    "save_file.close()\n",
    "\n",
    "ifps_data = pd.read_csv(\"data0928/ifps0928_refined.csv\")\n",
    "raw_ifps_type = ifps_data['type'].values\n",
    "\n",
    "\n",
    "#save_file = open('daily_HFC_data_matrix_agg.npy','rb')\n",
    "#agg_preds = np.load(save_file)\n",
    "#agg_se = np.load(save_file)\n",
    "##agg_openday = np.load(save_file)\n",
    "### Truth a vector of {1,2} where 1 means the event happen with probability 1\n",
    "##truth = np.load(save_file)\n",
    "#save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.   3.   2.   2.   1.   4.   2.   4.   2.   1.   5.   2.   2.   2.   1.\n",
      "   2.   2.   2.   2.   2.   5.   3.   2.   4.   1.   2.   5.   2.   1.   1.\n",
      "   1.   5.   4.  nan   3.   2.   4.   1.   2.   2.   1.   3.   1.   4.   1.\n",
      "   2.   2.   5.   2.   2.   2.   3.   3.   3.   1.   2.   4.   2.   2.   1.\n",
      "   2.   1.   2.   1.   3.   2.   2.   5.   2.   1.   2.   2.   1.   2.   3.\n",
      "   2.   1.   1.   3.  nan   2.   2.   4.   3.   2.   2.   1.   2.   1.   1.\n",
      "   3.   1.   2.   2.   1.   1.   3.   3.   4.   1.   2.   1.  nan   2.   2.\n",
      "   1.   2.   2.   1.   1.   4.   5.   1.   1.   3.   1.   5.   5.   2.   3.\n",
      "   2.   2.   2.   1.   3.   2.   2.   2.   2.   2.   3.   3.   2.   2.   1.\n",
      "   1.   1.   1.   1.   2.   3.   1.   2.   2.   3.   3.   1.   2.   2.   1.\n",
      "   2.   2.   2.   2.   2.   4.   4.   2.   2.   3.   4.   1.   2.   2.   2.\n",
      "   1.   1.   2.   5.   2.   1.   3.   2.   2.   1.   1.   4.   4.   4.   2.\n",
      "   2.   3.   2.   2.   2.   2.   2.   2.   2.   4.   1.]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(truth)\n",
    "print(np.isnan(truth))\n",
    "print(~np.isnan(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 2 2 3 5 2 5 3 5 5 2 5 5 5 2 2 2 2 2 5 5 2 5 5 3 5 2 5 2 2 5 5 5 4 2 4\n",
      " 5 2 2 5 5 5 5 3 5 5 5 2 2 5 5 5 3 2 2 4 2 2 2 2 2 2 4 3 2 3 5 2 2 5 2 4 2\n",
      " 5 2 2 3 5 3 3 2 5 4 2 2 2 3 2 4 3 2 2 2 2 3 5 3 5 2 3 3 5 2 2 2 2 3 2 2 5\n",
      " 5 3 5 3 3 5 5 2 5 2 2 2 3 5 2 2 3 3 2 3 5 5 2 3 2 5 2 2 2 5 5 2 2 3 5 4 2\n",
      " 2 2 5 2 5 2 2 4 5 2 2 3 5 2 2 5 2 3 5 2 5 2 5 5 2 2 2 2 5 5 5 2 5 5 5 2 2\n",
      " 2 2 2 2 5 5]\n",
      "[  2.   3.   2.   2.   1.   4.   2.   4.   2.   1.   5.   2.   2.   2.   1.\n",
      "   2.   2.   2.   2.   2.   5.   3.   2.   4.   1.   2.   5.   2.   1.   1.\n",
      "   1.   5.   4.  nan   3.   2.   4.   1.   2.   2.   1.   3.   1.   4.   1.\n",
      "   2.   2.   5.   2.   2.   2.   3.   3.   3.   1.   2.   4.   2.   2.   1.\n",
      "   2.   1.   2.   1.   3.   2.   2.   5.   2.   1.   2.   2.   1.   2.   3.\n",
      "   2.   1.   1.   3.  nan   2.   2.   4.   3.   2.   2.   1.   2.   1.   1.\n",
      "   3.   1.   2.   2.   1.   1.   3.   3.   4.   1.   2.   1.  nan   2.   2.\n",
      "   1.   2.   2.   1.   1.   4.   5.   1.   1.   3.   1.   5.   5.   2.   3.\n",
      "   2.   2.   2.   1.   3.   2.   2.   2.   2.   2.   3.   3.   2.   2.   1.\n",
      "   1.   1.   1.   1.   2.   3.   1.   2.   2.   3.   3.   1.   2.   2.   1.\n",
      "   2.   2.   2.   2.   2.   4.   4.   2.   2.   3.   4.   1.   2.   2.   2.\n",
      "   1.   1.   2.   5.   2.   1.   3.   2.   2.   1.   1.   4.   4.   4.   2.\n",
      "   2.   3.   2.   2.   2.   2.   2.   2.   2.   4.   1.]\n",
      "(185, 191, 1175, 5)\n",
      "(185, 191, 1175)\n",
      "(185, 191, 1175)\n",
      "(185, 191, 1175)\n",
      "(185, 191)\n",
      "(185, 191, 1175)\n"
     ]
    }
   ],
   "source": [
    "openday = raw_openday[:]\n",
    "ifps_type = raw_ifps_type[:]\n",
    "truth = raw_truth[:]\n",
    "\n",
    "\n",
    "#valid = raw_user_type==1\n",
    "#valid = raw_user_type==2\n",
    "valid = raw_user_type==3\n",
    "#valid = raw_user_type>0\n",
    "#indicator = raw_indicator[:, :, valid]\n",
    "preds = raw_preds[:, :, valid]\n",
    "conf = raw_conf[:, :, valid]\n",
    "wager = raw_wager[:, :, valid]\n",
    "se = raw_se[:, :, valid]\n",
    "user_type = raw_user_type[valid]\n",
    "preds_age = raw_preds_age[:, :, valid]\n",
    "\n",
    "\n",
    "#print(preds)\n",
    "print(ifps_type)\n",
    "print(truth)\n",
    "print(preds.shape)\n",
    "print(conf.shape)\n",
    "print(wager.shape)\n",
    "print(se.shape)\n",
    "print(openday.shape)\n",
    "print(preds_age.shape)\n",
    "#print(agg_preds.shape)\n",
    "#print(openday[35:70].T)\n",
    "#print(agg_openday[35:70].T)\n",
    "#print(ifps_data[['map_id','type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, euclidean\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MBS(preds, truth):\n",
    "    #print(preds.shape, truth.shape)\n",
    "    preds = np.array(preds)\n",
    "    truth = np.array(truth)\n",
    "    preds[preds<-0.1] = np.NAN\n",
    "    if np.sum(~np.isnan(preds))<=0:\n",
    "        return np.NAN, np.ones(len(truth)) * np.NAN\n",
    "    \n",
    "    score = np.NAN * np.ones_like(truth)\n",
    "    resolved = ~np.isnan(truth)\n",
    "    preds = preds[resolved]\n",
    "    truth = truth[resolved].astype(int)\n",
    "    truth = truth - 1\n",
    "    preds_of_true_label = preds[np.arange(len(truth))[:, None], truth[:, None]].squeeze()\n",
    "    #preds_of_true_label = preds[np.arange(len(truth))[:, None], truth[:, None]].flatten()\n",
    "    score[resolved] = np.sum(preds**2, axis=-1) - preds_of_true_label**2 + (1-preds_of_true_label)**2\n",
    "    #print(score.shape)\n",
    "    return np.nanmean(score), score\n",
    "\n",
    "def mean_aggr(preds, weights=None):\n",
    "    if weights is None: return np.nanmean(preds, axis=1)\n",
    "    weights = np.array(weights)\n",
    "    weights[np.isnan(preds[:,:,0])] = np.NAN\n",
    "    ret = np.nansum(preds * weights[:, :, None], axis=1) / (np.nansum(weights, axis=1)[:, None])\n",
    "    #print(preds.shape, weights.shape, ret.shape)\n",
    "    #print(np.nanmax(np.nansum(ret, axis=1)), np.nanmin(np.nansum(ret, axis=1)))\n",
    "    #print(ret[7])\n",
    "    return ret\n",
    "\n",
    "def median_aggr(preds):\n",
    "    n, m, k = preds.shape\n",
    "    median_pred = -np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        users = ~np.isnan(preds[i, :, 0])\n",
    "        median_pred[i] = geometric_median(preds[i, users, :])\n",
    "    return median_pred\n",
    "\n",
    "def majority_aggr(preds):\n",
    "    n, m, k = preds.shape\n",
    "    major_pred = np.zeros((n, k))\n",
    "    major_pred[np.arange(n)[:, None], np.argmax(np.nanmean(preds, axis=1), axis=-1)[:, None]] = 1.0\n",
    "    return major_pred\n",
    "\n",
    "def logit_aggr(preds, ifps_type=None, weights=None, para={2: 1.4, 3: 1.4, 4: 1.4, 5: 1.4}):\n",
    "    n, m, k = preds.shape\n",
    "    if ifps_type is None: ifps_type = 2 * np.ones(n)\n",
    "    logit_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        num_outcome = int(ifps_type[i])\n",
    "        a = para[num_outcome]\n",
    "        valid = preds[i, :, 0]>-0.1\n",
    "        curr_pred = preds[i, valid, :]\n",
    "        if ~(weights is None): \n",
    "            curr_weights = weights[i, valid]\n",
    "        else: \n",
    "            curr_weights = np.ones(np.sum(valid))\n",
    "        if (np.sum(curr_pred[:, 0]>-0.1)<=0): continue\n",
    "        logit_pred[i] = 0\n",
    "        base_dim = 0#ifps_type[i] - 1\n",
    "        logits = np.array(curr_pred).T\n",
    "        logits[base_dim, logits[base_dim]>=1] = 0.999\n",
    "        logits[base_dim, logits[base_dim]<=0] = 0.001\n",
    "        logit_pred[i, base_dim] = 1\n",
    "        for k in range(0, num_outcome):\n",
    "            if k==base_dim: continue\n",
    "            logits[k, logits[k]>=1] = 0.999\n",
    "            logits[k, logits[k]<=0] = 0.001\n",
    "            logits[k] = np.log(logits[k]/logits[base_dim])\n",
    "            mean = np.average(logits[k], weights=curr_weights)\n",
    "            logit_pred[i, k] = np.exp(a * mean)\n",
    "        logit_pred[i] = logit_pred[i] / np.sum(logit_pred[i])\n",
    "        #print(\"qid: \", i, \"type: \", ifps_type[i], \"logit: \", logit_pred[i])\n",
    "        \n",
    "    return logit_pred\n",
    "\n",
    "def entropy_matrix(pred_matrix, axis=-1):\n",
    "    type_matrix = np.zeros_like(pred_matrix)\n",
    "    type_matrix[pred_matrix<0] = -1\n",
    "    type_matrix[(pred_matrix>0) & (pred_matrix<1)] = 1\n",
    "    entropy_matrix = np.array(pred_matrix)\n",
    "    entropy_matrix[type_matrix<1] = 0.5\n",
    "    entropy_matrix = -entropy_matrix * np.log(entropy_matrix)\n",
    "    entropy_matrix[type_matrix==0] = 0\n",
    "    entropy_matrix[type_matrix==-1] = np.NAN\n",
    "    return np.sum(entropy_matrix, axis=axis)\n",
    "    \n",
    "    \n",
    "def prob_weighted_aggr(preds, openday):\n",
    "    n, m = preds.shape\n",
    "    prob_weighted_pred = -1 * np.ones(n)\n",
    "    for i in range(n):\n",
    "        if openday[i]==0: continue\n",
    "        if (np.sum(preds[i, :]>-0.1)<=0): continue\n",
    "        probs = preds[i, :]\n",
    "        probs = probs[probs>-0.1]\n",
    "        prob_weighted_pred[i] = np.average(probs, weights=np.abs(probs-0.5))\n",
    "    return prob_weighted_pred\n",
    "\n",
    "def entropy_weighted_aggr(preds, ifps_type):\n",
    "    n, m, k = preds.shape\n",
    "    entr_weighted_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        users = ~np.isnan(preds[i,:,0])\n",
    "        curr_pred = preds[i, users]\n",
    "        entr_weights = entropy_matrix(curr_pred)\n",
    "        entr_weights = (np.log(ifps_type[i]) - entr_weights) / np.log(ifps_type[i])\n",
    "        entr_weights = entr_weights ** 4\n",
    "        entr_weighted_pred[i] = np.average(curr_pred, weights=entr_weights, axis=0)\n",
    "    return entr_weighted_pred\n",
    "\n",
    "def conf_weighted_aggr(preds, conf):\n",
    "    n, m, k = preds.shape\n",
    "    conf_weighted_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        users = ~np.isnan(preds[i,:,0])\n",
    "        curr_conf = conf[i, users]\n",
    "        curr_pred = preds[i, users]\n",
    "        if np.sum(curr_conf)<=0: continue\n",
    "        conf_weighted_pred[i] = np.average(curr_pred, weights=curr_conf, axis=0)\n",
    "    return conf_weighted_pred\n",
    "\n",
    "def top_conf_aggr(preds, conf, top=10):\n",
    "    n, m, k = preds.shape\n",
    "    conf_weighted_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        valid = ~np.isnan(preds[i,:,0])\n",
    "        curr_conf = conf[i, valid]\n",
    "        curr_pred = preds[i, valid]\n",
    "        if np.sum(curr_conf>=80)>=top:\n",
    "            users = (curr_conf>=80)\n",
    "        elif np.sum(curr_conf>=70)>=top:\n",
    "            users = (curr_conf>=70)\n",
    "            #print(\"conf:\", i, 70, np.sum(conf[i, :]>=80))\n",
    "        elif np.sum(curr_conf>50)>=top:\n",
    "            users = (curr_conf>50)\n",
    "        elif np.sum(curr_conf>=50)>=top:\n",
    "            users = (curr_conf>=50)\n",
    "        else: users = (curr_conf>=0)\n",
    "        if np.sum(users)<=0: continue\n",
    "        curr_conf = curr_conf[users]\n",
    "        curr_pred = curr_pred[users]\n",
    "        if np.max(curr_conf)<=0.0:\n",
    "            curr_conf[:] = 1\n",
    "        elif np.max(curr_conf)-np.min(curr_conf)>0:\n",
    "            curr_conf = (curr_conf - np.min(curr_conf)) / (np.max(curr_conf)-np.min(curr_conf))\n",
    "        conf_weighted_pred[i] = np.average(curr_pred, weights=curr_conf, axis=0)\n",
    "    return conf_weighted_pred\n",
    "\n",
    "def wager_weighted_aggr(preds, wager, wager_option):\n",
    "    n, m, k = preds.shape\n",
    "    wager_weighted_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        users = ~np.isnan(preds[i,:,0])\n",
    "        curr_wager = wager[i, users] + 10 * wager_option[users]\n",
    "        #print(curr_wager)\n",
    "        if np.sum(curr_wager>0)<=0: continue\n",
    "        curr_pred = preds[i, users]\n",
    "        wager_weighted_pred[i] = np.average(curr_pred, weights=curr_wager, axis=0)\n",
    "    return wager_weighted_pred\n",
    "\n",
    "def top_wager_aggr(preds, wager, wager_option, base_weight=5):\n",
    "    n, m, k = preds.shape\n",
    "    wager_weighted_pred = -1 * np.ones((n, k))\n",
    "    for i in range(n):\n",
    "        users = ~np.isnan(preds[i,:,0])\n",
    "        curr_wager = wager[i, users]\n",
    "        curr_wager[curr_wager==100] = base_weight\n",
    "        curr_wager[curr_wager==0] = base_weight\n",
    "        num_wagered_users = np.sum(curr_wager>0)\n",
    "        if num_wagered_users<=0: continue\n",
    "        order = np.argsort(curr_wager)\n",
    "        curr_wager[order[:-10]] = 0\n",
    "        curr_pred = preds[i, users]\n",
    "        wager_weighted_pred[i] = np.average(curr_pred, weights=curr_wager, axis=0)\n",
    "    return wager_weighted_pred\n",
    "\n",
    "def openday_filter(preds, openday):\n",
    "    n, m = preds.shape\n",
    "    new_preds = -1 * np.ones_like(preds)\n",
    "    for i in range(n):\n",
    "        if openday[i]==0: continue\n",
    "        new_preds[i] = preds[i]\n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computing weights!\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:4016: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1313: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "Finish computing weights!\n"
     ]
    }
   ],
   "source": [
    "# Compute weights\n",
    "t, n, m, k = preds.shape\n",
    "print(\"Start computing weights!\")\n",
    "w_f = np.zeros((t,n,m)) # weights based on update frequency\n",
    "w_a = np.zeros((t, m)) # weights based on accuracy\n",
    "preds_num = np.zeros((n,m)) # the number of forecasts made by user j on IFP i\n",
    "average_relative_daily_BS = np.zeros((n,m))\n",
    "resolved_num = 0 \n",
    "coverage_num = np.zeros(m) # the number of \n",
    "daily_coverage_rate = np.zeros((t,m)) # the percentage of IFPs answered by a user over all resolved IFP\n",
    "daily_accur_score = np.zeros((t,m)) # the accuracy score of a user \n",
    "relative_se = np.array(se)\n",
    "relative_se[relative_se<-0.1] = np.NAN\n",
    "for i in range(t):\n",
    "    if i%20==0: print(i)\n",
    "    preds_num[preds_age[i,:,:]==0] += 1 # on day i, the preds_age==0 means a new prediction made\n",
    "    for j in range(n):\n",
    "        if openday[i,j]>0: # IFP j open\n",
    "            relative_se[i,j,:] -= 0.7 * np.nanmedian(relative_se[i,j,:])\n",
    "            w_f[i,j,:] = preds_num[j,:]/openday[i,j]\n",
    "            w_f[i,j] = (w_f[i,j] - np.min(w_f[i,j])) / (np.max(w_f[i,j])-np.min(w_f[i,j])) * 0.9 + 0.1\n",
    "        elif openday[i,j]<-0.1: # IFP j close\n",
    "            relative_se[i,j,:] = np.NAN\n",
    "        if (openday[i,j]) == -2 and (openday[i-1, j]>=-1): # IFP j is just resolved\n",
    "            if np.isnan(relative_se[:, j, :]).all(): continue\n",
    "            tmp = np.exp(np.nansum(relative_se[:,j,:], axis=0)) # Calculate the average relative daily BS within IFP j\n",
    "            tmp = (tmp-np.nanmean(tmp))/np.nanstd(tmp) # Standardize the average relative daily BS within IFP j\n",
    "            average_relative_daily_BS[j, :] = tmp\n",
    "            resolved_num += 1\n",
    "            coverage_num += preds[i,j,:,0]>-0.1\n",
    "            \n",
    "    if resolved_num >= 1:\n",
    "        daily_coverage_rate[i, :] = coverage_num / resolved_num\n",
    "        daily_accur_score[i, :] = np.nanmean(average_relative_daily_BS[:,:], axis=0) # mean accross resolved IFPs. \n",
    "        \n",
    "    if resolved_num >=10:\n",
    "        w_a[i, :] = 0\n",
    "        valid = daily_coverage_rate[i, k]>=0.4\n",
    "        w_a[i, valid] = daily_accur_score[i, valid]\n",
    "        w_a[i] = (w_a[i] - np.min(w_a[i])) / (np.max(w_a[i])-np.min(w_a[i])) * 0.9 + 0.1\n",
    "    else:\n",
    "        w_a[i] = 0.1\n",
    "    #print(w_f[i, 7:8, 3:10], st.mode(w_f[i, 7, :]))\n",
    "    #print(np.isnan(w_f).any(), np.isnan(w_a).any())\n",
    "    \n",
    "\n",
    "#    print(se[i,7:8, 2:10])\n",
    "#    print(relative_se[i,7:8, 2:10])\n",
    "#    print(\"!\", average_relative_daily_BS[7:8, 2:10])\n",
    "#    print(openday[i, 7:8])\n",
    "    \n",
    "#        for j in range(n):\n",
    "\n",
    "            \n",
    "        \n",
    "print(\"Finish computing weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 191 1175 5\n",
      "0\n",
      "20\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in less\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "t, n, m, k = preds.shape\n",
    "print(t, n, m, k)\n",
    "num = np.zeros((t,n))\n",
    "BS_mean = np.NAN * np.ones((t, n))\n",
    "MBS_mean = np.NAN * np.ones(t)\n",
    "BS_median = np.NAN * np.ones((t, n))\n",
    "MBS_median = np.NAN * np.ones(t)\n",
    "BS_logit = np.NAN * np.ones((t, n))\n",
    "MBS_logit = np.NAN * np.ones(t)\n",
    "BS_prob_weighted = np.NAN * np.ones((t, n))\n",
    "MBS_prob_weighted = np.NAN * np.ones(t)\n",
    "BS_entr_weighted = np.NAN * np.ones((t, n))\n",
    "MBS_entr_weighted = np.NAN * np.ones(t)\n",
    "BS_conf_weighted = np.NAN * np.ones((t, n))\n",
    "MBS_conf_weighted = np.NAN * np.ones(t)\n",
    "BS_top_conf = np.NAN * np.ones((t, n))\n",
    "MBS_top_conf = np.NAN * np.ones(t)\n",
    "BS_wager_weighted = np.NAN * np.ones((t, n))\n",
    "MBS_wager_weighted = np.NAN * np.ones(t)\n",
    "BS_top_wager = np.NAN * np.ones((t, n))\n",
    "MBS_top_wager = np.NAN * np.ones(t)\n",
    "BS_major = np.NAN * np.ones((t, n))\n",
    "MBS_major = np.NAN * np.ones(t)\n",
    "BS_sur1_majority_happen = np.NAN * np.ones((t, n))\n",
    "MBS_sur1_majority_happen = np.NAN * np.ones(t)\n",
    "BS_sur1_minority_happen = np.NAN * np.ones((t, n))\n",
    "MBS_sur1_minority_happen = np.NAN * np.ones(t)\n",
    "BS_sur2_majority_happen = np.NAN * np.ones((t, n))\n",
    "MBS_sur2_majority_happen = np.NAN * np.ones(t)\n",
    "BS_sur2_minority_happen = np.NAN * np.ones((t, n))\n",
    "MBS_sur2_minority_happen = np.NAN * np.ones(t)\n",
    "SE = np.NAN * np.ones((t, n))\n",
    "\n",
    "#l = agg_preds.shape[-1]\n",
    "#BS_agg = np.NAN * np.ones((l, t, n))\n",
    "#MBS_agg = np.NAN * np.ones((l, t))\n",
    "\n",
    "preds_num = np.zeros((n,m))\n",
    " \n",
    "\n",
    "PERC_DECAY = 1\n",
    "e_f = 3\n",
    "e_a = 1\n",
    "sur_error_rate_days = 0\n",
    "for i in range(t):\n",
    "    if i%20==0: print(i)\n",
    "    curr_pred = np.array(preds[i])\n",
    "    curr_preds_age = np.array(preds_age[i])\n",
    "    num[i] = np.sum(curr_pred[:, :, 0]>-0.1, axis=1)*(openday[i]>=1)\n",
    "    answered_ifps = num[i]>0\n",
    "    if np.sum(answered_ifps)<=0: continue\n",
    "    \n",
    "    curr_pred = curr_pred[answered_ifps, :, :]\n",
    "    curr_preds_age = curr_preds_age[answered_ifps, :]\n",
    "    curr_pred[curr_pred<-0.1] = np.NAN\n",
    "    \n",
    "    #Remove old preds for each IFP\n",
    "    for j in range(len(curr_pred)):\n",
    "        ages = curr_preds_age[j]\n",
    "        ages = np.sort(ages[ages>-0.1])\n",
    "        max_allowed_age = ages[int(PERC_DECAY*len(ages))-1]\n",
    "        #print('!', np.sum(~np.isnan(curr_pred[j])))\n",
    "        curr_pred[j, curr_preds_age[j]>max_allowed_age] = np.NAN\n",
    "        #print('!!', np.sum(~np.isnan(curr_pred[j])))\n",
    "        \n",
    "    w_matrix = (w_f[i, answered_ifps, :]**e_f) * (w_a[i, None, :]**e_a)\n",
    "    #print(np.min(w_matrix), np.max(w_matrix))\n",
    "    #print(w_matrix.shape,w_a[i, None, :].shape)\n",
    "    #afs\n",
    "        \n",
    "    # Control the number of predictions in aggregation for experimental purpose\n",
    "    #for j in range(len(curr_pred)):\n",
    "    #    while (np.sum(~np.isnan(curr_pred[j, :, 0]))>26):\n",
    "    #        index = np.argwhere(~np.isnan(curr_pred[j, :, 0]))\n",
    "    #        curr_pred[j, index[int(np.random.randint(0, len(index)))], :] = np.NAN\n",
    "    \n",
    "    mean_pred = -np.ones((n, k))\n",
    "    median_pred = -np.ones((n, k))\n",
    "    logit_pred = -np.ones((n, k))\n",
    "    entr_weighted_pred = -np.ones((n, k))\n",
    "    conf_weighted_pred = -np.ones((n,k))\n",
    "    top_conf_pred = -np.ones((n,k))\n",
    "    wager_weighted_pred = -np.ones((n,k))\n",
    "    top_wager_pred = -np.ones((n,k))\n",
    "    major_pred = -np.ones((n,k))\n",
    "    \n",
    "    mean_pred[answered_ifps] = mean_aggr(curr_pred, weights=w_matrix)\n",
    "    median_pred[answered_ifps] = median_aggr(curr_pred)\n",
    "    logit_pred[answered_ifps] = logit_aggr(curr_pred, ifps_type[answered_ifps], weights=w_matrix)\n",
    "    entr_weighted_pred[answered_ifps] = entropy_weighted_aggr(curr_pred, ifps_type[answered_ifps])\n",
    "    conf_weighted_pred[answered_ifps] = conf_weighted_aggr(curr_pred, conf[i][answered_ifps,:])\n",
    "    top_conf_pred[answered_ifps] = conf_weighted_aggr(curr_pred, conf[i][answered_ifps,:])\n",
    "    wager_weighted_pred[answered_ifps] = wager_weighted_aggr(curr_pred, wager[i][answered_ifps,:], user_type<3)\n",
    "    top_wager_pred[answered_ifps] = wager_weighted_aggr(curr_pred, wager[i][answered_ifps,:], user_type<3)\n",
    "    major_pred[answered_ifps] = majority_aggr(curr_pred)\n",
    "    \n",
    "    MBS_mean[i], BS_mean[i] = MBS(mean_pred, truth)\n",
    "    MBS_median[i], BS_median[i] = MBS(median_pred, truth)\n",
    "    MBS_logit[i], BS_logit[i] = MBS(logit_pred, truth)\n",
    "    MBS_entr_weighted[i], BS_entr_weighted[i] = MBS(entr_weighted_pred, truth)\n",
    "    MBS_conf_weighted[i], BS_conf_weighted[i] = MBS(conf_weighted_pred, truth)\n",
    "    MBS_top_conf[i], BS_top_conf[i] = MBS(top_conf_pred, truth)\n",
    "    MBS_wager_weighted[i], BS_wager_weighted[i] = MBS(wager_weighted_pred, truth)\n",
    "    MBS_top_wager[i], BS_top_wager[i] = MBS(top_wager_pred, truth)\n",
    "    MBS_major[i], BS_major[i] = MBS(major_pred, truth)\n",
    "    \n",
    "    #multi_preds_ifps = np.sum(preds[i]>-0.1, axis=1)>=3\n",
    "    #if (sur_error_rate_days<10 or sur_error_rate_days%10==0) and np.sum(multi_preds_ifps)>0:\n",
    "    #    print(\"day: \"+str(i))\n",
    "    #    err_ind_majority_happen, P0_est_majority_happen = sur_error_rate(preds[i][multi_preds_ifps,:], P0=0.51)\n",
    "    #    err_ind_minority_happen, P0_est_minority_happen = sur_error_rate(preds[i][multi_preds_ifps,:], P0=0.49)\n",
    "        \n",
    "    #if not (np.isnan(P0_est_majority_happen) or np.isnan(P0_est_minority_happen)):            \n",
    "    #    sur_error_rate_days += 1\n",
    "    #    curr_open_preds = openday_filter(np.array(preds[i]), openday[i])\n",
    "    #    sur1_pred_majority_happen = sur_agg_1(curr_open_preds, err_ind_majority_happen, P0_est_majority_happen)\n",
    "    #    sur1_pred_minority_happen = sur_agg_1(curr_open_preds, err_ind_minority_happen, P0_est_minority_happen)\n",
    "    #    sur2_pred_majority_happen = sur_agg_2(curr_open_preds, err_ind_majority_happen)\n",
    "    #    sur2_pred_minority_happen = sur_agg_2(curr_open_preds, err_ind_minority_happen)\n",
    "    #    sur1_pred_majority_happen[sur1_pred_majority_happen>1] = 1\n",
    "    #    sur1_pred_minority_happen[sur1_pred_minority_happen>1] = 1\n",
    "    #    sur2_pred_majority_happen[sur2_pred_majority_happen>1] = 1\n",
    "    #    sur2_pred_minority_happen[sur2_pred_minority_happen>1] = 1\n",
    "    #    MBS_sur1_majority_happen[i], BS_sur1_majority_happen[i] = MBS(sur1_pred_majority_happen, truth)         \n",
    "    #    MBS_sur1_minority_happen[i], BS_sur1_minority_happen[i] = MBS(sur1_pred_minority_happen, truth)\n",
    "    #    MBS_sur2_majority_happen[i], BS_sur2_majority_happen[i] = MBS(1.0*sur2_pred_majority_happen, truth)\n",
    "    #    MBS_sur2_minority_happen[i], BS_sur2_minority_happen[i] = MBS(1.0*sur2_pred_minority_happen, truth)\n",
    "        \n",
    "        \n",
    "    #openday_agg_preds = openday_filter(np.array(agg_preds[i]), openday[i])\n",
    "    #for j in range(l):\n",
    "    #    MBS_agg[j, i], BS_agg[j, i, :] = MBS(openday_agg_preds[:, j], truth)\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4341  0.4335  0.4807  0.4171  0.4273  0.4273     nan     nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: Mean of empty slice\n",
      "  \n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: Mean of empty slice\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: Mean of empty slice\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice\n",
      "  \n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: Mean of empty slice\n",
      "  import sys\n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: Mean of empty slice\n",
      "  \n",
      "/Users/heliaguin/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: Mean of empty slice\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "start_day = 0\n",
    "print(np.array([np.nanmean([np.nanmean(BS_mean[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_median[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_logit[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_entr_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_conf_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_top_conf[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_wager_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_top_wager[start_day:, i]) for i in range(n)])\n",
    "#                np.nanmean([np.nanmean(BS_sur1_majority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur1_minority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur2_majority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur2_minority_happen[start_day:, i]) for i in range(n)])\n",
    "               ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_matrix = np.zeros((t, n))\n",
    "for i in range(t):\n",
    "    num_matrix[i, :] = np.sum(conf[i, :, :]>-0.1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "cuts = np.linspace(0,1,11)\n",
    "BS_cut_matrix = np.ones((8, len(cuts), n)) * np.NAN\n",
    "\n",
    "num_preds = np.ones(n) * np.NAN\n",
    "days = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    BS_matrix_one_IFP = np.vstack((BS_mean[:, i], BS_median[:, i], BS_logit[:, i], BS_entr_weighted[:, i],\n",
    "                                   BS_conf_weighted[:, i], BS_top_conf[:, i],\n",
    "                                   BS_wager_weighted[:, i], BS_top_wager[:, i]\n",
    "                                  ))\n",
    "    num_methods = len(BS_matrix_one_IFP)\n",
    "    days[i] = np.sum(~np.isnan(BS_matrix_one_IFP[0,:]))\n",
    "    if days[i]<=13: continue\n",
    "    tmp_mean_scores = np.zeros(num_methods)\n",
    "    for j in range(num_methods):\n",
    "        tmp = BS_matrix_one_IFP[j, :]\n",
    "        valid = ~np.isnan(tmp)\n",
    "        tmp = tmp[valid]\n",
    "        tmp_days = len(tmp)\n",
    "        for c in range(len(cuts)):\n",
    "            BS_cut_matrix[j, c, i] = tmp[int(np.round(cuts[c]*(tmp_days-1)))]\n",
    "epoch += 1\n",
    "total_BS_cut_matrix += BS_cut_matrix\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "plot_BS_cut_matrix = total_BS_cut_matrix[:]/epoch\n",
    "plt.figure(1)\n",
    "labels = ['Mean', 'Median', 'Logit', 'Entropy w.', 'Conf w.', 'Top conf.']\n",
    "markers = ['o', '*', 's', 'v', '^','p']\n",
    "for i in [0, 1, 2, 3, 5]:\n",
    "    x = cuts * 100\n",
    "    y = np.nanmean(BS_cut_matrix[i], axis=1)\n",
    "    #print(y)\n",
    "    plt.plot(x, y, '-'+markers[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('Life of an IFP (%)')\n",
    "plt.ylabel('Mean Brier score')\n",
    "plt.savefig(\"/Users/heliaguin/Desktop/11.jpg\", dpi=150,\n",
    "            bbox_inches='tight', pad_inches=0.1\n",
    "           )\n",
    "plt.show()\n",
    "plt.close('All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch=0\n",
    "total_BS_cut_matrix = np.zeros_like(BS_cut_matrix)\n",
    "print(total_BS_cut_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BS_num_matrix = np.zeros((8, 121))\n",
    "BS_num_matrix[:, 10] = np.array([ 0.4283,0.4222,0.4247,0.459, 0.5053,0.5053,0.4346,0.4346])\n",
    "BS_num_matrix[:, 20] = np.array([ 0.4168,0.4053,0.3939,0.4035,0.482, 0.482, 0.4215,0.4215])\n",
    "BS_num_matrix[:, 30] = np.array([ 0.4135,0.3999,0.3804,0.3804,0.4548,0.4548,0.4145,0.4145])\n",
    "BS_num_matrix[:, 40] = np.array([ 0.4136,0.3988,0.3793,0.3716,0.4435,0.4435,0.4262,0.4262])\n",
    "BS_num_matrix[:, 50] = np.array([ 0.4119,0.3971,0.3734,0.3591,0.4268,0.4268,0.4218,0.4218])\n",
    "BS_num_matrix[:, 60] = np.array([ 0.4112,0.3959,0.3716,0.3555,0.4141,0.4141,0.4184,0.4184])\n",
    "BS_num_matrix[:, 70] = np.array([ 0.4107,0.3948,0.3695,0.352, 0.4043,0.4043,0.4157,0.4157])\n",
    "BS_num_matrix[:, 80] = np.array([ 0.4097,0.3939,0.3673,0.3484,0.3963,0.3963,0.4138,0.4138])\n",
    "BS_num_matrix[:, 90] = np.array([ 0.4102,0.3941,0.367, 0.3457,0.3884,0.3884,0.4097,0.4097])\n",
    "BS_num_matrix[:, 100] = np.array([ 0.4095,0.3932,0.3661,0.346, 0.3866,0.3866,0.4079,0.4079])\n",
    "BS_num_matrix[:, 110] = np.array([ 0.4095,0.3928,0.3655,0.3446,0.3826,0.3826,0.4094,0.4094])\n",
    "BS_num_matrix[:, 120] = np.array([ 0.4092,0.3928,0.3647,0.3429,0.3805,0.3805,0.4067,0.4067])\n",
    "\n",
    "x = [(i+1)* 10 for i in range(12)]\n",
    "plt.figure(1)\n",
    "labels = ['Mean', 'Median', 'Logit', 'Entropy w.', 'Conf w.', 'Top conf.']\n",
    "markers = ['o', '*', 's', 'v', '^','p']\n",
    "for i in [0, 1, 2, 3, 5]:\n",
    "    y = BS_num_matrix[i][x]\n",
    "    #print(y)\n",
    "    plt.plot(x, y, '-'+markers[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('Maximum # of predictions selected')\n",
    "plt.ylabel('Mean Brier score')\n",
    "plt.savefig(\"/Users/heliaguin/Desktop/2.jpg\", dpi=150,\n",
    "            bbox_inches='tight', pad_inches=0.1\n",
    "           )\n",
    "plt.show()\n",
    "plt.close('All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "#BS_mean_open = np.ones(n) * np.NAN\n",
    "#BS_median_open = np.ones(n) * np.NAN\n",
    "#BS_logit_open = np.ones(n) * np.NAN\n",
    "#BS_entr_open = np.ones(n) * np.NAN\n",
    "#BS_conf_weighted_open = np.ones(n) * np.NAN\n",
    "#BS_top_conf_open = np.ones(n) * np.NAN\n",
    "#BS_wager_weighted_open = np.ones(n) * np.NAN\n",
    "#BS_top_wager_open = np.ones(n) * np.NAN\n",
    "\n",
    "num_preds = np.ones(n) * np.NAN\n",
    "BS_period_matrix = []\n",
    "days = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    BS_matrix_one_IFP = np.vstack((BS_mean[:, i], BS_median[:, i], BS_logit[:, i], BS_entr_weighted[:, i],\n",
    "                                   BS_conf_weighted[:, i], BS_top_conf[:, i],\n",
    "                                   BS_wager_weighted[:, i], BS_top_wager[:, i]\n",
    "                                  ))\n",
    "    num_methods = len(BS_matrix_one_IFP)\n",
    "    days[i] = np.sum(~np.isnan(BS_matrix_one_IFP[0,:]))\n",
    "    if days[i]<=13: continue\n",
    "    tmp_mean_scores = np.zeros(num_methods)\n",
    "    for j in range(num_methods):\n",
    "        tmp = BS_matrix_one_IFP[j, :]\n",
    "        valid = ~np.isnan(tmp)\n",
    "        tmp = tmp[valid]\n",
    "        tmp_days = len(tmp)\n",
    "        #tmp = tmp[:int(np.round(0.5*tmp_days))]\n",
    "        #tmp = tmp[int(np.round(0.7*tmp_days)):]\n",
    "        tmp = tmp[-1].reshape((-1))\n",
    "        tmp_mean_scores[j] = np.mean(tmp)\n",
    "        num_preds[i] = np.sum(num_matrix[valid, i][0])/ len(tmp)\n",
    "    BS_period_matrix.append(tmp_mean_scores)\n",
    "BS_period_matrix = np.array(BS_period_matrix)\n",
    "print(BS_period_matrix.shape)\n",
    "print(np.mean(BS_period_matrix, axis=0))\n",
    "\n",
    "print(\"p value:\")\n",
    "p_values = np.zeros(num_methods)\n",
    "for i in range(num_methods):\n",
    "    tmp, p_values[i] = st.ttest_1samp(BS_period_matrix[:, 0] - BS_period_matrix[:, i], popmean=0)\n",
    "p_values /= 2\n",
    "p_values[p_values<=0.05] = 1\n",
    "print(p_values)\n",
    "for i in range(num_methods):\n",
    "    tmp, p_values[i] = st.ttest_1samp(BS_period_matrix[:, 3] - BS_period_matrix[:, i], popmean=0)\n",
    "p_values /= 2\n",
    "p_values[p_values<=0.05] = 1\n",
    "print(p_values)\n",
    "print(np.nansum(num_preds)/np.nansum(num_preds>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(days).replace('.', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aaa(pred_matrix, P0, trials = 100):\n",
    "    n, m = pred_matrix.shape\n",
    "    #agg_pred = logit_aggr(pred_matrix)\n",
    "    tmp = np.array(pred_matrix)\n",
    "    tmp[tmp<-0.1] = np.NAN\n",
    "    agg_pred = np.nanmean(tmp, axis=1)\n",
    "    agg_labels_multi_trials = np.zeros((n, trials))\n",
    "    for i in range(trials):\n",
    "        labels = 2 - (np.random.rand(n) < agg_pred)\n",
    "        agg_labels_multi_trials[:, i] = labels\n",
    "    agg_labels_multi_trials[:, 0] = 2 - (0.5 < agg_pred)\n",
    "    #print(agg_labels_multi_trials[:, 0])\n",
    "    #print(agg_labels_multi_trials.shape)\n",
    "    #print(agg_labels_multi_trials)\n",
    "    err_ind, P0_est = sur_error_rate(pred_matrix, eval_labels=agg_labels_multi_trials, P0=P0)\n",
    "    #err_ind, P0_est = sur_error_rate(last_pred, eval_labels=agg_labels_multi_trials[:, 0][:,None], P0=0.49)\n",
    "    err_ind = np.array(err_ind)\n",
    "    err_agg = np.mean(err_ind, axis=0)\n",
    "    print(err_agg)\n",
    "    if np.isnan(err_agg).any():\n",
    "        return np.ones_like(pred_matrix) * np.NAN, err_agg\n",
    "    #print(err_ind.shape)\n",
    "    #print(err_ind)\n",
    "    #print(P0_est)\n",
    "    \n",
    "    sur_score_matrix = estimate_sur_score(pred_matrix, agg_pred, err_agg)\n",
    "    #print(np.min(sur_score_matrix[~np.isnan(sur_score_matrix)]),\n",
    "    #      np.max(sur_score_matrix[~np.isnan(sur_score_matrix)]))\n",
    "    print(np.nanmean(sur_score_matrix))\n",
    "    #print(sur_score_matrix)\n",
    "    #sur_score = estimate_sur_score(np.array(1 * (0.5 < agg_pred))[:, None], agg_pred[:], err_agg)\n",
    "    #sur_score = estimate_sur_score(0.5 * np.ones((n,1)), agg_pred, err_agg)\n",
    "    #print(sur_score)\n",
    "    #print(np.mean(sur_score))\n",
    "    return sur_score_matrix, err_agg\n",
    "\n",
    "t, n, m, k = preds.shape\n",
    "print(t, n, m, k)\n",
    "num = np.zeros((t,n))\n",
    "BS_sur_weighted_maj = np.NAN * np.ones((t, n))\n",
    "MBS_sur_weighted_maj = np.NAN * np.ones(t)\n",
    "BS_sur_weighted_min = np.NAN * np.ones((t, n))\n",
    "MBS_sur_weighted_min = np.NAN * np.ones(t)\n",
    "BS_logit = np.NAN * np.ones((t, n))\n",
    "MBS_logit = np.NAN * np.ones(t)\n",
    "BS_mean = np.NAN * np.ones((t, n))\n",
    "MBS_mean = np.NAN * np.ones(t)\n",
    "sur_error_rate_days = 0\n",
    "for i in range(t):\n",
    "    if i%20==0: print(i)\n",
    "    curr_pred = np.array(preds[i])\n",
    "    num[i] = np.sum(curr_pred[:, :, 0]>-0.1, axis=1)*openday[i]\n",
    "    answered_ifps = num[i]>0\n",
    "    if np.sum(answered_ifps)<=0: continue\n",
    "    \n",
    "    curr_pred = curr_pred[answered_ifps, :, :]\n",
    "    curr_pred[curr_pred<-0.1] = np.NAN\n",
    "    \n",
    "    mean_pred = -np.ones((n, k))\n",
    "    logit_pred = -np.ones((n, k))\n",
    "    sur_weighted_pred_maj = -np.ones((n, k))\n",
    "    sur_weighted_pred_min = -np.ones((n, k)) \n",
    "    \n",
    "    mean_pred[answered_ifps] = mean_aggr(curr_pred)\n",
    "    logit_pred[answered_ifps] = logit_aggr(curr_pred, ifps_type[answered_ifps])\n",
    "    \n",
    "    MBS_logit[i], BS_logit[i] = MBS(logit_pred, truth)\n",
    "    MBS_mean[i], BS_mean[i] = MBS(mean_pred, truth)\n",
    "    \n",
    "    # using all predictions including those closed to calculate error rate\n",
    "    valid_ifps = (ifps_type == 2) & (np.sum(preds[i, :, :, 0]>-0.1, axis=1)>=3)\n",
    "    print(\"sur_day\", sur_error_rate_days)\n",
    "    if np.sum(valid_ifps)>0:\n",
    "        sur_error_rate_days += 1\n",
    "    if sur_error_rate_days>=30 and sur_error_rate_days%10==0 and np.sum(valid_ifps)>0:\n",
    "        print(\"day: \"+str(i))\n",
    "        valid_preds = np.array(preds[i, valid_ifps, :, 0])\n",
    "        valid_preds = valid_preds.reshape((np.sum(valid_ifps), -1))\n",
    "        sur_score_matrix_maj, err_agg_maj = aaa(valid_preds, P0=0.51)\n",
    "        sur_score_matrix_min, err_agg_min = aaa(valid_preds, P0=0.49)\n",
    "    #    err_agg_minority = aaa(valid_preds, P0=0.49)\n",
    "    #    err_ind_minority_happen, P0_est_minority_happen = sur_error_rate(preds[i][multi_preds_ifps,:], P0=0.49)\n",
    "\n",
    "        \n",
    "    if (~np.isnan(err_agg_maj).any()) and (np.sum(err_agg_maj)<0.55) and (sur_error_rate_days>=30):\n",
    "        sur_weighted_pred_maj[answered_ifps] = sur_weighted_aggr(curr_pred, sur_score_matrix_maj,\n",
    "                                                                 ifps_type[answered_ifps])\n",
    "        MBS_sur_weighted_maj[i], BS_sur_weighted_maj[i] = MBS(sur_weighted_pred_maj, truth)\n",
    "        print('Day '+str(i)+\" logit MBS:\", MBS_logit[i])\n",
    "        print('Day '+str(i)+\" sur maj MBS:\", MBS_sur_weighted_maj[i],\" sur BS:\", BS_sur_weighted_maj[i])\n",
    "    else: sur_weighted_pred_maj[answered_ifps] = mean_pred[answered_ifps]\n",
    "    \n",
    "    if (~np.isnan(err_agg_min).any()) and (np.sum(err_agg_min)<0.55) and (sur_error_rate_days>=30):\n",
    "        sur_weighted_pred_min[answered_ifps] = sur_weighted_aggr(curr_pred, sur_score_matrix_min,\n",
    "                                                                 ifps_type[answered_ifps])\n",
    "        MBS_sur_weighted_min[i], BS_sur_weighted_min[i] = MBS(sur_weighted_pred_min, truth)\n",
    "        print('Day '+str(i)+\" logit MBS:\", MBS_logit[i])\n",
    "        print('Day '+str(i)+\" sur min MBS:\", MBS_sur_weighted_min[i],\" sur BS:\", BS_sur_weighted_min[i])\n",
    "    else: sur_weighted_pred_min[answered_ifps] = mean_pred[answered_ifps]\n",
    "        \n",
    "    MBS_sur_weighted_maj[i], BS_sur_weighted_maj[i] = MBS(sur_weighted_pred_maj, truth)\n",
    "    MBS_sur_weighted_min[i], BS_sur_weighted_min[i] = MBS(sur_weighted_pred_min, truth)\n",
    "    #    curr_open_preds = openday_filter(np.array(preds[i]), openday[i])\n",
    "    #    sur1_pred_majority_happen = sur_agg_1(curr_open_preds, err_ind_majority_happen, P0_est_majority_happen)\n",
    "    #    sur1_pred_minority_happen = sur_agg_1(curr_open_preds, err_ind_minority_happen, P0_est_minority_happen)\n",
    "    #    sur2_pred_majority_happen = sur_agg_2(curr_open_preds, err_ind_majority_happen)\n",
    "    #    sur2_pred_minority_happen = sur_agg_2(curr_open_preds, err_ind_minority_happen)\n",
    "    #    sur1_pred_majority_happen[sur1_pred_majority_happen>1] = 1\n",
    "    #    sur1_pred_minority_happen[sur1_pred_minority_happen>1] = 1\n",
    "    #    sur2_pred_majority_happen[sur2_pred_majority_happen>1] = 1\n",
    "    #    sur2_pred_minority_happen[sur2_pred_minority_happen>1] = 1\n",
    "    #    MBS_sur1_majority_happen[i], BS_sur1_majority_happen[i] = MBS(sur1_pred_majority_happen, truth)         \n",
    "    #    MBS_sur1_minority_happen[i], BS_sur1_minority_happen[i] = MBS(sur1_pred_minority_happen, truth)\n",
    "    #    MBS_sur2_majority_happen[i], BS_sur2_majority_happen[i] = MBS(1.0*sur2_pred_majority_happen, truth)\n",
    "    #    MBS_sur2_minority_happen[i], BS_sur2_minority_happen[i] = MBS(1.0*sur2_pred_minority_happen, truth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_day = 0\n",
    "print(np.array([np.nanmean([np.nanmean(BS_sur_weighted_maj[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_sur_weighted_min[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_logit[start_day:, i]) for i in range(n)])\n",
    "               ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_day = 0\n",
    "print(np.array([np.nanmean([np.nanmean(BS_mean[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_median[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_logit[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_entr_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_conf_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_wager_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_major[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_sur_weighted_maj[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_sur_weighted_min[start_day:, i]) for i in range(n)])\n",
    "               ]))\n",
    "\n",
    "\n",
    "baseline = np.array([np.nanmean(BS_mean[start_day:, i]) for i in range(n)])\n",
    "sur = np.array([np.nanmean(BS_sur_weighted_maj[start_day:, i]) for i in range(n)])\n",
    "valid = (~np.isnan(baseline)) & (~np.isnan(sur))\n",
    "baseline = baseline[valid]\n",
    "sur = sur[valid]\n",
    "t_score, p_value = st.ttest_1samp(sur - baseline, popmean=0)\n",
    "p_value = p_value / 2\n",
    "print(\"t, p value(one_tail): \", t_score, p_value)\n",
    "\n",
    "#print(BS_conf_weighted[:, :7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num[num==0] = np.NAN\n",
    "\n",
    "#print(MBS_sur1_minority_happen)\n",
    "#print(MBS_sur2_minority_happen)\n",
    "#print(MBS_logit)\n",
    "#print(np.nanmean(MBS_mean[30:]), np.nanmean(MBS_median[30:]), np.nanmean(MBS_logit[30:]),\n",
    "#      np.nanmean(MBS_prob_weighted[30:]), np.nanmean(MBS_conf_weighted[30:]), \n",
    "#      np.nanmean(MBS_wager_weighted[30:]))\n",
    "\n",
    "start_day = 0\n",
    "print(np.array([np.nanmean([np.nanmean(BS_mean[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_median[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_logit[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_entr_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_conf_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_wager_weighted[start_day:, i]) for i in range(n)])\n",
    "#                np.nanmean([np.nanmean(BS_sur1_majority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur1_minority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur2_majority_happen[start_day:, i]) for i in range(n)]),\n",
    "#                np.nanmean([np.nanmean(BS_sur2_minority_happen[start_day:, i]) for i in range(n)])\n",
    "               ]))\n",
    "\n",
    "for i in np.array([np.nanmean([np.nanmean(BS_mean[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_median[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_logit[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_entr_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_conf_weighted[start_day:, i]) for i in range(n)]),\n",
    "                np.nanmean([np.nanmean(BS_wager_weighted[start_day:, i]) for i in range(n)])\n",
    "               ]):\n",
    "    print(i)\n",
    "\n",
    "\n",
    "#aver_dailymean_BS_within_IFPs = np.zeros(l)\n",
    "#for i in range(l):\n",
    "#    aver_dailymean_BS_within_IFPs[i] = np.nanmean([np.nanmean(BS_agg[i, :, j]) for j in range(n)])\n",
    "#agg_stats = pd.read_csv('agg_map.csv')\n",
    "#agg_stats = agg_stats.rename(columns={'Unnamed: 0':'agg_name'})\n",
    "#agg_stats['MMBS_within_IFP'] = aver_dailymean_BS_within_IFPs\n",
    "#agg_names = agg_stats['agg_name'].values\n",
    "\n",
    "    \n",
    "plt.figure(1)\n",
    "#plt.plot(np.arange(t), MBS_mean, label='mean')\n",
    "plt.plot(np.arange(t), MBS_median, label='median')\n",
    "plt.plot(np.arange(t), MBS_logit, label='logit')\n",
    "plt.plot(np.arange(t), MBS_entr_weighted, label='entropy')\n",
    "#plt.plot(np.arange(t), MBS_conf_weighted, label='conf')\n",
    "#plt.plot(np.arange(t), MBS_wager_weighted, label='wager')\n",
    "#plt.plot(np.arange(t), MBS_sur_weighted_maj, label='sur_maj')\n",
    "plt.plot(np.arange(t), MBS_sur_weighted_min, label='sur_min')\n",
    "plt.ylabel('Mean Brier Score')\n",
    "plt.xlabel('Day')\n",
    "plt.xlim([0, 130])\n",
    "#plt.ylim([0, 2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "qid = 15\n",
    "plt.figure(1)\n",
    "plt.plot(np.arange(t), BS_mean[:, qid], label='mean')\n",
    "plt.plot(np.arange(t), BS_median[:, qid], label='median')\n",
    "plt.plot(np.arange(t), BS_logit[:, qid], label='logit')\n",
    "plt.plot(np.arange(t), BS_entr_weighted[:, qid], label='entropy')\n",
    "#plt.plot(np.arange(t), MBS_conf_weighted, label='conf')\n",
    "#plt.plot(np.arange(t), MBS_wager_weighted, label='wager')\n",
    "plt.plot(np.arange(t), BS_sur_weighted_maj[:, qid], label='sur_maj')\n",
    "#plt.plot(np.arange(t), MBS_sur_weighted_min, label='sur_min')\n",
    "plt.ylabel('Mean Brier Score')\n",
    "plt.xlabel('Day')\n",
    "plt.xlim([0, 130])\n",
    "#plt.ylim([0, 2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "\n",
    "\n",
    "asdad\n",
    "plt.figure(2)\n",
    "agg_idx = np.argsort(aver_dailymean_BS_within_IFPs)\n",
    "#print(aver_dailymean_BS_within_IFPs[agg_idx])\n",
    "for i in range(5):\n",
    "    agg_id = agg_idx[i]\n",
    "    plt.plot(np.arange(t), MBS_agg[agg_id,:], label=agg_names[agg_id])    \n",
    "plt.ylabel('Mean Brier Score')\n",
    "plt.xlabel('Day')\n",
    "plt.xlim([0, 100])\n",
    "#plt.ylim([0, 2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('All')\n",
    "\n",
    "print(agg_stats.columns)\n",
    "agg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time weighted average BS\n",
    "\n",
    "print(np.nanmean(MBS_mean), np.nanmean(MBS_median), np.nanmean(MBS_logit),\n",
    "      np.nanmean(MBS_prob_weighted), np.nanmean(MBS_conf_weighted), \n",
    "      np.nanmean(MBS_wager_weighted))\n",
    "\n",
    "time_discount_BS_mean = np.zeros(n)\n",
    "time_discount_BS_median = np.zeros(n)\n",
    "time_discount_BS_logit = np.zeros(n)\n",
    "time_discount_BS_prob = np.zeros(n)\n",
    "time_discount_BS_conf = np.zeros(n)\n",
    "time_discount_BS_wager = np.zeros(n)\n",
    "# np.isnan(.) is the same for all BS_*, except for wager\n",
    "for i in range(n):\n",
    "    l = np.sum(BS_mean[:, i]>-0.1)\n",
    "    if l <= 0: continue\n",
    "    #weights = np.linspace(2, 1, l)\n",
    "    weights = np.ones(l)\n",
    "    time_discount_BS_mean[i] += np.average(BS_mean[~np.isnan(BS_mean[:, i]), i], weights=weights)\n",
    "    time_discount_BS_median[i] += np.average(BS_median[~np.isnan(BS_mean[:, i]), i], weights=weights)\n",
    "    time_discount_BS_logit[i] += np.average(BS_logit[~np.isnan(BS_mean[:, i]), i], weights=weights)\n",
    "    time_discount_BS_prob[i] += np.average(BS_prob_weighted[~np.isnan(BS_mean[:, i]), i], weights=weights)\n",
    "    time_discount_BS_conf[i] += np.average(BS_conf_weighted[~np.isnan(BS_mean[:, i]), i], weights=weights)\n",
    "    l = np.sum(BS_wager_weighted[:, i]>-0.1)\n",
    "    if l <= 0: continue\n",
    "    #weights = np.linspace(2, 1, l)\n",
    "    weights = np.ones(l)\n",
    "    time_discount_BS_wager[i] += np.average(BS_wager_weighted[~np.isnan(BS_wager_weighted[:, i]), i],\n",
    "                                            weights=weights)\n",
    "    \n",
    "# np.sum(time_discount_BS_*>0) is the same for all *, except for wager\n",
    "td_MBS_mean = np.sum(time_discount_BS_mean) / np.sum(time_discount_BS_mean>0)\n",
    "td_MBS_median = np.sum(time_discount_BS_median) / np.sum(time_discount_BS_mean>0)\n",
    "td_MBS_logit = np.sum(time_discount_BS_logit) / np.sum(time_discount_BS_mean>0)\n",
    "td_MBS_prob = np.sum(time_discount_BS_prob) / np.sum(time_discount_BS_mean>0)\n",
    "td_MBS_conf = np.sum(time_discount_BS_conf) / np.sum(time_discount_BS_mean>0)\n",
    "td_MBS_wager = np.sum(time_discount_BS_wager) / np.sum(time_discount_BS_wager>0)\n",
    "print(td_MBS_mean, td_MBS_median, td_MBS_logit, td_MBS_prob, td_MBS_conf, td_MBS_wager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ifp_map_id = 0\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(np.arange(t), BS_mean[:, ifp_map_id], label=\"mean\")\n",
    "plt.plot(np.arange(t), BS_median[:, ifp_map_id], label=\"median\")\n",
    "plt.plot(np.arange(t), BS_logit[:, ifp_map_id], label=\"logit\")\n",
    "plt.plot(np.arange(t), BS_prob_weighted[:, ifp_map_id], label=\"prob\")\n",
    "plt.plot(np.arange(t), BS_conf_weighted[:, ifp_map_id], label=\"conf\")\n",
    "plt.plot(np.arange(t), BS_wager_weighted[:, ifp_map_id], label=\"wager\")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Mean Brier Score')\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(np.arange(t), num[:, ifp_map_id], 'k--')\n",
    "plt.ylabel('# of predictions')\n",
    "plt.show()\n",
    "\n",
    "plt.close('All')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
